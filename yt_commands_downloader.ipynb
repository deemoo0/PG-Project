{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTX-fl2jFRey",
        "outputId": "7998fd6a-28b1-4001-d82b-163957afd662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.12/dist-packages (2026.1.31)\n",
            "Starting download for: https://www.youtube.com/watch?v=dlHu-gAyglw\n",
            "Found 1 comments. Processing...\n",
            "\n",
            "SUCCESS! Downloaded 1 comments.\n",
            "File saved as: youtube_comments.csv\n",
            "First 5 rows:\n",
            "              author                                               text  \\\n",
            "0  @YuttaSihingGusti  thanks for your informatin. its work for me. g...   \n",
            "\n",
            "    timestamp  likes  \n",
            "0  1769904000      0  \n"
          ]
        }
      ],
      "source": [
        "# 1. Install the downloader tool (Run this once)\n",
        "!pip install yt-dlp\n",
        "\n",
        "import csv\n",
        "from yt_dlp import YoutubeDL\n",
        "import pandas as pd\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Paste the YouTube URL of the video you want to analyze here\n",
        "video_url = \"https://www.youtube.com/watch?v=dlHu-gAyglw\"\n",
        "\n",
        "# --- THE DOWNLOADER SCRIPT ---\n",
        "def download_youtube_comments(url):\n",
        "    print(f\"Starting download for: {url}\")\n",
        "\n",
        "    # Options tailored for extracting text only (no video/audio)\n",
        "    opts = {\n",
        "        \"getcomments\": True,\n",
        "        \"skip_download\": True,      # Don't download the video file\n",
        "        \"quiet\": True,              # Less clutter in output\n",
        "        \"no_warnings\": True,\n",
        "        \"ignore_no_formats_error\": True,\n",
        "        \"extractor_args\": {\n",
        "            \"youtube\": {\n",
        "                \"max_comments\": [\"all\"],       # Download ALL comments (or change to [\"500\"] for speed)\n",
        "                \"player_client\": [\"web_safari\"] # Mimic a browser to avoid blocking\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "\n",
        "    comments_data = []\n",
        "\n",
        "    with YoutubeDL(opts) as yt:\n",
        "        try:\n",
        "            info = yt.extract_info(url, download=False)\n",
        "            raw_comments = info.get(\"comments\") or []\n",
        "\n",
        "            print(f\"Found {len(raw_comments)} comments. Processing...\")\n",
        "\n",
        "            # Extract only the data needed for your Data Science Project\n",
        "            for c in raw_comments:\n",
        "                comments_data.append({\n",
        "                    \"author\": c.get(\"author\"),\n",
        "                    \"text\": c.get(\"text\"),           # This is your main input for NLP\n",
        "                    \"timestamp\": c.get(\"timestamp\"), # Essential for Demand Forecasting (Time Series)\n",
        "                    \"likes\": c.get(\"like_count\")     # Proxy for Sentiment/Agreement\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    # --- SAVE TO CSV ---\n",
        "    if comments_data:\n",
        "        filename = \"youtube_comments.csv\"\n",
        "        # Create a DataFrame for clean formatting\n",
        "        df = pd.DataFrame(comments_data)\n",
        "\n",
        "        # Save to CSV (utf-8-sig handles Emojis correctly)\n",
        "        df.to_csv(filename, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "        print(f\"\\nSUCCESS! Downloaded {len(df)} comments.\")\n",
        "        print(f\"File saved as: {filename}\")\n",
        "        print(\"First 5 rows:\")\n",
        "        print(df.head())\n",
        "    else:\n",
        "        print(\"No comments found or video is private/restricted.\")\n",
        "\n",
        "# Run the function\n",
        "download_youtube_comments(video_url)"
      ]
    }
  ]
}